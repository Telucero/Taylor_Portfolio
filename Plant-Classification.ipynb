{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1>2021 Data Science Kaggle Project </h1> \n<h3> Plant Classification </h3> \n<p> This is the group DataScience Kaggle Project for the Polytech' Nice Data Science course 2021. In this project we will be analyzing, constructing, and modeling Neural Networks to evaluate images for plant classification.</p>\n\n<body>\n    <b><h2> Members of Team Chikorita: </h2></b>  \n    <ul>\n        <li><h4> Ilaria Enache </h4></li>\n        <li><h4> Lenny Klump </h4></li>\n        <li><h4> Lynda Attouche </h4></li>\n        <li><h4> Taylor Lucero </h4></li>\n    </ul>\n\n   <span style = \"position:relative; left:350px; top:-130px\"><img src=\"https://cdn.shopify.com/s/files/1/1034/3311/files/cymbidium-sp-pink-and-white-orchid-flowers-picture-id1093448542.jpg?v=1554867402\" alt=\"Orchid\" height=450px width=450px > </span>\n       \n</body>","metadata":{}},{"cell_type":"markdown","source":"## **Documentation**\n\nThe project is focused on plant classification. The dataset used is a subset of the public Pl@ntNet Dataset, it contains 140,256 images from 153 species.\nWe started by importing the required libraries for the project. We used pandas for data processing, torch for the deep learning framework, torchvision for the datasets, pre-trained models and manipulation functions, skimat for image preprocessing and seaborn for statistical graphs.\n\n## **Exploration and analysis of the data**\n\nFor the data analysis we wanted to find statistics about our data.\nWe first loaded the data, either the class file or the images. We decided to create a dataframe that will contain them with their label and the \"scientific\" name of the label. We decided to do this because it was more practical for us to handle and it turned out to be the case. \n\n## **Preprocessing**\n\nThe data preprocessing has been applied to the whole dataset, to all images. \n\n**Transformation and data augmentation**\n\n* Resizing Images: we resized our images from 600x600 to 224x224 to suit some models input as Resnet\n* Normalization of images: so that all data are at the same scale which accelerates the training phase.\n* Converting  images to tensor\n* Data augmentation:to diversify the images, we have applied different techniques: RandomHorizontalFlip(), RandomRotation(50),..\n\n\n**Splitting data** \n\nSince we do not have a valid test already defined in the data, we have divided our data set into two parts: a train set which will be used for training our model and a validation set which will be used for testing it when learning our neural network. To do this we chose to divide it as follows: 75% train set and 15% valid set.\n\n**Resampling data**\n\nDuring the analysis, we observed that the distribution of the images by classes was highly unbalanced (see graph...) which could affect our result in the end. \nSo we decided to treat it in two different ways:\n    \n1) *Oversampling and undersampling:*\nThe goal here was to oversample the classes with a low number of images and undersample the ones with a lot.  To do so, we tested several sizes: 7000, 3000, 2000,1000,100\nFrom these tests, sometimes, by oversampling we were easily confronted with an overfitting and by undersampling with an underfitting.\n\n2) *Resampling using weightedRandomSampler:*\nTo apply this pytorch technique, we calculated the weight of each class and image. After that, the dataloader had to use the sample of classes with the highest weight. When testing this method, we obtained bad results, in particular for the accuracy. \n\n## **Model Experiments**\n\n**Timeline** \n\nIn order to maximize tests, we created two notebooks, where two persons tested independently. In the last week we chose the notebook which achieved a better accuracy and continued improving there. \n\n**Notebook 1:**\n\n* First the LeNet5 Model was tested (similar to the Lab), but obviously gave very bad results due to enormous downsizing (600x600 to 28x28) and grayscale instead of RGB. \n* Afterwards AlexNet was tested, with various transformations (Resize, RandomFlip, Normalization). However the Architecture gave very bad results (val accuracy around 1% on first Epoch) \n* Then the world of pretrained models was discovered, and the VGG16 model was tested. Again various transformations were applied and NLLLoss and Adam optimizer were utilized. However the model again gave bad accuracy (val accuracy 5% on first epoch).\n* After, we discovered that the dataset is extremely unbalanced so weighting the Loss function was tried but didn’t work out due to different class orders (coding mistake). \n* Then we continued trying to optimize the VGG16 model (different batch sizes, LossFunctions, optimizers,...) and finally got a validation accuracy of 56% with NLLLOss() and Adam optimizer. This was our best result so far. \n* After that, the ResNet architecture was tried: ResNet50, ResNet101 and ResNet152, where ResNet152 yielded the best results. Here, we also tried different Loss Functions and optimizers and finally achieved a validation accuracy of 72,5% with CrossEntropyLoss and Adam optimizer. This improved our best result.\n* After that other things were tried: Weighted Loss, VGG19 architecture, EfficientNe_b7 architecture, using larger Images, Inception_v3 architecture. And all architectures with different Learning rates, batch sizes etc. However, nothing improved our current score. \n\nBecause in Notebook 2 a scheduler was implemented, which seemed to work really well, the author of Notebook1 switched to work also on the code of Notebook2.\n\n**Notebook2:**\n\nWe tested a couple of neural network models until we found the one that allows us to have the best score. We have in this case used pre-trained models.\n\n* To start, 3 models of the resnets family have been applied to our data set. Indeed, these models have the potential to have a good performance on image classification. With deep layers, they allowed us to have good accuracy values. \nWe have tested at the very beginning resnet50 whose architecture includes 50 deep layers. This one provided us with a good accuracy. However, to get more, looking at the amount of data we had, we thought that testing resnet101 and resnet152 would give a much better result. But it turns out that this was not the case.\n\n* Another model known for its performance in image classification that we tested is the VGG-16. It allowed us to have the best accuracy at that time of the test and so we continued to work with it. Afterwards, another version was tested, the VGG19. But this one unfortunately could not provide a better score. \n\n* Moreover, we were curious to test another model, the efficientNet. A model which is based on a scaling method (scaling dimensions) that uses a set of fixed scaling coefficients. But this model did not converge to a better score.\n\n* *Parameters tests*: In addition to testing different models, we have varied the parameters of our networks.\n    * **Batch size**: We tested 4 values: 32, 64, 128, 256. In the end we ended up with 64\n\n    * **Epochs**: It depended on the model, some of them performed in less epochs than others. But in general we ran our models on : 5, 10, 15 epochs. We wanted to test on more (which required more than 9 hours) but Kaggle did not allow that (max. 9h Runtime)..\n\n    * **Loss function**: We tested and used in our final model crossEntropy() because it was the best adapted for a multi-class classification. However, we also tested NNLoss()\n\n    * **Optimize**: We tested Stochastic Gradient Descent (SGD) with a momentum of 0.9 as well as Adam Optimizer. For the final result, we settled on the latter because it was the best. \n\n    * **Scheduler**: Having seen that the performance is not really increasing, we have introduced a new method for updating the learning rate: the scheduler. Indeed, this last one allows us to reduce the learning rate as the epochs increase. We have tested two types: CyclicLR which will be used for the final model and StepLR().\n\n\n* During different tests various learning rates and batch sizes were tested on the pretrained VGG16 version with scheduler. Also, and most importantly, new transformations were applied. Using “RandomResizedCrop” instead of “Resize” and increasing the Epochs yielded us a new highest score: val_accuracy of 89,3% and when submitting a score of 82.6%. \n\n* Because of this high discrepancy between our validation score and the submission score we assumed that the test data isn’t following the same distribution as the Training data. So we revisited the concept of oversampling by manually balancing the images per class. Also, we applied even more transformations to increase generalizability: “ColorJitter”.  We ran our best scrong model with balanced data in two ways: \n    * 1. 2000 images per class and 6 epochs: This yielded  a validation accuracy of 76,5%. \n    * 2. 1000 imager per class and 12 epochs: This yielded a validation accuracy of 92%, which was a new best score. However, the submission score was only 74%.On the day of the deadline, we found out why the model didn’t perform well on submission: While balancing the classes we put a range(1,153) which only included 152 classes… A range (1,154) was needed. \n    \n  **Visualisation**\n  In the model, we made slight variations from the model worked on in the lab. These changes include gradient banks for both the training and validation sets, a iteration counter for both, and a gradient and store. Once the model begins training, the gradients calculated will then be appended after each epoch into these banks  for further use with seaborn. After this the information pulled from the model is converted into a Dataframe using a defined function where the data will be plotted in a series of code to produce visuals for the validation and training sets focusing on the gradients, accuracy, and loss. In these cases we want the gradient to be minimized, showing a plot decreasing and then plateuing. Accuracy to increase gradually after each epoch, showing that the model is learning. Loss to decrease gradually to show help calculate the gradients and show the models error during the training iterations. \n\n\n**Model Predictions** \n\nTo predict the labels of the test data we created a loop and stored the results in a panda’s dataframe. To order the images we used a left join on the sample submission. \n\n\n\n","metadata":{}},{"cell_type":"code","source":"# Importing needed libraries: \n\n# Linear Algebra:\nimport numpy as np \nimport matplotlib.pyplot as plt \n\n# Data Processing, CSV file I/O (e.g. pd.read_csv):\nimport pandas as pd \n\n# Directories:\nimport os\n\n# Pytorch & torchvision\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision.transforms import ToTensor\nfrom torch.autograd import Variable\nfrom torch.optim.lr_scheduler import CyclicLR\nfrom torchvision import models\n\n# Visualization:\nimport seaborn as sns\n\n# Data Splitting:\nfrom sklearn.model_selection import train_test_split\n\n# Images: \nfrom PIL import Image\nfrom IPython.display import display\nimport matplotlib.image as img\nfrom skimage import io\n\n# Others: \nimport random\nfrom tqdm.notebook import tqdm\n\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-30T20:45:17.657139Z","iopub.execute_input":"2021-11-30T20:45:17.657621Z","iopub.status.idle":"2021-11-30T20:45:17.665769Z","shell.execute_reply.started":"2021-11-30T20:45:17.657577Z","shell.execute_reply":"2021-11-30T20:45:17.66503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. Data Exploration & Analysis","metadata":{}},{"cell_type":"code","source":"#Data paths\ndata_dir = '/kaggle/input/polytech-nice-data-science-course-2021/polytech/'\ntrain_dir = data_dir+'train'\ntest_dir = data_dir+'test'\nlabels_file = data_dir+'/class_names.csv'","metadata":{"execution":{"iopub.status.busy":"2021-11-30T20:45:17.667632Z","iopub.execute_input":"2021-11-30T20:45:17.668399Z","iopub.status.idle":"2021-11-30T20:45:17.677491Z","shell.execute_reply.started":"2021-11-30T20:45:17.66836Z","shell.execute_reply":"2021-11-30T20:45:17.676744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checking the list of the entries in data dir\nos.listdir('/kaggle/input/polytech-nice-data-science-course-2021/polytech/')","metadata":{"execution":{"iopub.status.busy":"2021-11-30T20:45:17.678923Z","iopub.execute_input":"2021-11-30T20:45:17.679258Z","iopub.status.idle":"2021-11-30T20:45:17.693323Z","shell.execute_reply.started":"2021-11-30T20:45:17.679224Z","shell.execute_reply":"2021-11-30T20:45:17.692679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check how many images we have in each subfolder of the train folder\n# for that we use os.walk\nfor dir_path, folder, files in os.walk(train_dir):\n   print(f\"There are {len(folder)} directories and {len(files)} images in '{dir_path}'.\")","metadata":{"execution":{"iopub.status.busy":"2021-11-30T20:45:17.694311Z","iopub.execute_input":"2021-11-30T20:45:17.694497Z","iopub.status.idle":"2021-11-30T20:45:17.698581Z","shell.execute_reply.started":"2021-11-30T20:45:17.694474Z","shell.execute_reply":"2021-11-30T20:45:17.697749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# here it gives us how many images we have in the test folder\nfor dir_path, folder, files in os.walk(test_dir):\n    print(f\"There are {len(folder)} directories and {len(files)} images in '{dir_path}'.\")","metadata":{"execution":{"iopub.status.busy":"2021-11-30T20:45:17.701222Z","iopub.execute_input":"2021-11-30T20:45:17.701472Z","iopub.status.idle":"2021-11-30T20:45:24.688218Z","shell.execute_reply.started":"2021-11-30T20:45:17.70144Z","shell.execute_reply":"2021-11-30T20:45:24.68739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1.1 Loading classes","metadata":{}},{"cell_type":"code","source":"# dataframe for labels\nclasses = pd.read_csv(labels_file)","metadata":{"execution":{"iopub.status.busy":"2021-11-30T20:45:24.689455Z","iopub.execute_input":"2021-11-30T20:45:24.69017Z","iopub.status.idle":"2021-11-30T20:45:24.702256Z","shell.execute_reply.started":"2021-11-30T20:45:24.690122Z","shell.execute_reply":"2021-11-30T20:45:24.701489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# displaying the 5 first rows of the dataframe\nclasses.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-30T20:45:24.729731Z","iopub.execute_input":"2021-11-30T20:45:24.731766Z","iopub.status.idle":"2021-11-30T20:45:24.744362Z","shell.execute_reply.started":"2021-11-30T20:45:24.731729Z","shell.execute_reply":"2021-11-30T20:45:24.743392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# total number of classes we have\nclasses.count()","metadata":{"execution":{"iopub.status.busy":"2021-11-30T20:45:24.767285Z","iopub.execute_input":"2021-11-30T20:45:24.769385Z","iopub.status.idle":"2021-11-30T20:45:24.782163Z","shell.execute_reply.started":"2021-11-30T20:45:24.76935Z","shell.execute_reply":"2021-11-30T20:45:24.781232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#checking if null/nan are contained in the dataframe\nclasses.isnull().values.any()","metadata":{"execution":{"iopub.status.busy":"2021-11-30T20:45:24.785919Z","iopub.execute_input":"2021-11-30T20:45:24.788015Z","iopub.status.idle":"2021-11-30T20:45:24.797511Z","shell.execute_reply.started":"2021-11-30T20:45:24.787979Z","shell.execute_reply":"2021-11-30T20:45:24.796855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1.2 Loading images ","metadata":{}},{"cell_type":"code","source":"images,id_species,species_name =[],[],[] #lists which contains image, encoded label and label name\nss = classes[' species_name'].tolist() #contains the labels name (e.g: Papaver_pseudoorientale)\n\n#for each folder (each class)\nfor fold in os.listdir(train_dir): # fold : name of the folder == name of the class\n    #for each image in the folder\n    for im in os.listdir(os.path.join(train_dir,fold)):\n           if os.path.splitext(im)[-1] == '.jpg': # pick only jpg files\n                images.append(im)\n                id_species.append(int(fold))\n                species_name.append(ss[int(fold)-1])    \n# create dataframe for our data\n# contains all images with their class (label encoded + label name)\ndata = {'id':images, 'id_species':id_species, 'species_name':species_name} \ndata = pd.DataFrame(data) ","metadata":{"execution":{"iopub.status.busy":"2021-11-30T20:45:24.815394Z","iopub.execute_input":"2021-11-30T20:45:24.818192Z","iopub.status.idle":"2021-11-30T20:45:25.354216Z","shell.execute_reply.started":"2021-11-30T20:45:24.818155Z","shell.execute_reply":"2021-11-30T20:45:25.353433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#displaying first 5 rows of the dataframe\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-30T20:45:25.35792Z","iopub.execute_input":"2021-11-30T20:45:25.358221Z","iopub.status.idle":"2021-11-30T20:45:25.373817Z","shell.execute_reply.started":"2021-11-30T20:45:25.358191Z","shell.execute_reply":"2021-11-30T20:45:25.373092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checking data shpe\ndata.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1.3 Data distribution","metadata":{}},{"cell_type":"code","source":"# dataframe that contains the class and number of images of this class\ncum = data['id_species'].value_counts().to_frame()\ncum['label'] = cum.index\ncumfig, ax = plt.subplots(figsize=(30,20))\n# displaying distribution of data as bar plot using seaborn \nsns.barplot(data=cum,x='label',y='id_species',ax=ax)","metadata":{"execution":{"iopub.status.busy":"2021-11-30T20:45:25.404598Z","iopub.execute_input":"2021-11-30T20:45:25.404852Z","iopub.status.idle":"2021-11-30T20:45:27.770579Z","shell.execute_reply.started":"2021-11-30T20:45:25.404819Z","shell.execute_reply":"2021-11-30T20:45:27.769914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1.4 Displaying images ","metadata":{}},{"cell_type":"code","source":"# display 5 images using imshow\nfig, axis = plt.subplots(1, 5, figsize=(20, 10))\nfor i, ax in enumerate(axis.flat):\n    path_ = os.path.join(str(data.loc[i,'id_species']),data.loc[i,'id'])\n    path = os.path.join(train_dir,path_)\n    ax.imshow(img.imread(path))","metadata":{"execution":{"iopub.status.busy":"2021-11-30T20:45:27.771883Z","iopub.execute_input":"2021-11-30T20:45:27.772335Z","iopub.status.idle":"2021-11-30T20:45:28.785484Z","shell.execute_reply.started":"2021-11-30T20:45:27.772295Z","shell.execute_reply":"2021-11-30T20:45:28.784882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Data Preprocessing","metadata":{}},{"cell_type":"markdown","source":"## 2.1 Resampling: Undersampling & Oversampling","metadata":{}},{"cell_type":"code","source":"def resample(i,n):\n    \"\"\"\n        Resampling class\n        args: \n            - i(int): class id \n            - n(int): size per class\n        return:\n            - class_i_sampled(dataframe): sampled class\n    \"\"\"\n    class_i = data[data.id_species==i]\n    count_class_i = class_i.id_species.value_counts()\n    # oversampling\n    # if the class has less images than n \n    if list(count_class_i)[0]<=n:\n        class_i_sampled = class_i.sample(n,replace=True)\n        #print(str(i)+','+str(class_i_sampled.id_species.value_counts()))\n    \n    # undersampling\n    # if the class has more images than n \n    else:\n        class_i_sampled = class_i.sample(n)\n        #print(str(i)+','+str(class_i_sampled.id_species.value_counts()))\n    return class_i_sampled\n\ndata_sampled = pd.DataFrame(columns=['id','id_species', 'species_name']) #contains the sampled data\n\n#loop around the classes\nfor i in range(1,153):\n    data_sampled=pd.concat([data_sampled,resample(i,1000)],ignore_index=True, sort=False)\n    \n# displying distribution of data in the new sampled dataset\ncum_sampled = data_sampled['id_species'].value_counts().to_frame()\ncum_sampled['id'] = cum_sampled.index\nfig, ax = plt.subplots(figsize=(30,20))\nsns.barplot(data=cum_sampled,x='id',y='id_species',ax=ax)","metadata":{"execution":{"iopub.status.busy":"2021-11-30T20:45:28.852757Z","iopub.execute_input":"2021-11-30T20:45:28.853171Z","iopub.status.idle":"2021-11-30T20:45:31.726592Z","shell.execute_reply.started":"2021-11-30T20:45:28.853135Z","shell.execute_reply":"2021-11-30T20:45:31.725875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2.2 Computing weights","metadata":{}},{"cell_type":"code","source":"def computing_weights(data):\n    \"\"\"\n        Computing weights of images\n        args: \n            - data(dataframe): data\n        return:\n            - weight(array): weight of each image\n    \"\"\"\n    #weight for each class\n    weights_class = np.zeros(154)\n    nb_data = len(data)\n    #loop on classes\n    for i in range(1,153):\n        weights_class[i] = float(nb_data)/cum[cum.label==i].values[0,0]\n    #weight for each image = weights of its class\n    weights = np.zeros(nb_data )\n    for idx,val in data.iterrows():\n        weights[idx] = weights_class[val['id_species']]\n    return weights","metadata":{"execution":{"iopub.status.busy":"2021-11-30T20:45:31.742519Z","iopub.execute_input":"2021-11-30T20:45:31.742966Z","iopub.status.idle":"2021-11-30T20:45:37.371842Z","shell.execute_reply.started":"2021-11-30T20:45:31.742922Z","shell.execute_reply":"2021-11-30T20:45:37.371032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#resampling \nweights = computing_weights(data)\ntrain_sampler = torch.utils.data.sampler.WeightedRandomSampler(weights, len(weights), replacement = True)      \nvalid_sampler = torch.utils.data.sampler.WeightedRandomSampler(weights, len(weights), replacement = True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2.3 Data augmentation & transformation","metadata":{}},{"cell_type":"code","source":"mean = [0.485,0.456,0.406]\nstd = [0.229,0.224,0.225]\n\n# transformations applied on train set\ntrain_transform = transforms.Compose([transforms.RandomResizedCrop(224),\n                                      transforms.ColorJitter(brightness=0.05, \n                                                             contrast=0.05, \n                                                             saturation=0.05),\n                                      transforms.RandomHorizontalFlip(),\n                                      transforms.RandomRotation(50),\n                                      transforms.ToTensor(),\n                                      transforms.Normalize(mean,std),\n                                     ])\n\n# transformations applied on val set\nvalid_transform = transforms.Compose([transforms.Resize(224),\n                                      transforms.RandomHorizontalFlip(),\n                                      transforms.RandomRotation(30),\n                                      transforms.ToTensor(),\n                                      transforms.Normalize(mean,std),\n                                     ])","metadata":{"execution":{"iopub.status.busy":"2021-11-30T20:45:37.373294Z","iopub.execute_input":"2021-11-30T20:45:37.373578Z","iopub.status.idle":"2021-11-30T20:45:37.381342Z","shell.execute_reply.started":"2021-11-30T20:45:37.373541Z","shell.execute_reply":"2021-11-30T20:45:37.380345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2.4 Creating custom dataset","metadata":{}},{"cell_type":"code","source":"# creating custom data to easily load, preprocess and augment data\nclass PlantDataset(Dataset):\n    def __init__(self, df, path , transform = None):\n        self.df = df\n        self.path = path\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self,index):\n        img_name,label,label_name = self.df.values[index]\n        img_path = os.path.join(self.path,str(label),img_name)\n        image = Image.open(img_path)\n        if self.transform is not None:\n            image = self.transform(image)\n            \n        return image, label","metadata":{"execution":{"iopub.status.busy":"2021-11-30T20:45:37.407192Z","iopub.execute_input":"2021-11-30T20:45:37.407692Z","iopub.status.idle":"2021-11-30T20:45:37.414935Z","shell.execute_reply.started":"2021-11-30T20:45:37.407653Z","shell.execute_reply":"2021-11-30T20:45:37.414167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2.5 Splitting data","metadata":{}},{"cell_type":"code","source":"# splitting data intro traind and valid sets using sklearn \ntrain, valid_data = train_test_split(data_sampled, test_size=0.15, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2021-11-30T20:45:37.415892Z","iopub.execute_input":"2021-11-30T20:45:37.418462Z","iopub.status.idle":"2021-11-30T20:45:37.441792Z","shell.execute_reply.started":"2021-11-30T20:45:37.418422Z","shell.execute_reply":"2021-11-30T20:45:37.441104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checking the split \nprint(len(train)+len(valid_data)==len(data_sampled))","metadata":{"execution":{"iopub.status.busy":"2021-11-30T20:45:37.443281Z","iopub.execute_input":"2021-11-30T20:45:37.443547Z","iopub.status.idle":"2021-11-30T20:45:37.45103Z","shell.execute_reply.started":"2021-11-30T20:45:37.443509Z","shell.execute_reply":"2021-11-30T20:45:37.450066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# creating custom dataset for each sub dataframe\ntrain_data = PlantDataset(train, train_dir, train_transform )\nvalid_data = PlantDataset(valid_data, train_dir, valid_transform )","metadata":{"execution":{"iopub.status.busy":"2021-11-30T20:45:37.452712Z","iopub.execute_input":"2021-11-30T20:45:37.452962Z","iopub.status.idle":"2021-11-30T20:45:37.458617Z","shell.execute_reply.started":"2021-11-30T20:45:37.45293Z","shell.execute_reply":"2021-11-30T20:45:37.457781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2.6 Data Loader","metadata":{}},{"cell_type":"code","source":"batch_size = 64","metadata":{"execution":{"iopub.status.busy":"2021-11-30T20:45:37.474836Z","iopub.execute_input":"2021-11-30T20:45:37.475789Z","iopub.status.idle":"2021-11-30T20:45:37.482622Z","shell.execute_reply.started":"2021-11-30T20:45:37.47575Z","shell.execute_reply":"2021-11-30T20:45:37.481892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loader = DataLoader(dataset = train_data,\n                          batch_size = batch_size,\n                          shuffle=True, \n                          #sampler = train_sampler <- with WeightedRandomSampler ,\n                          num_workers=2)\nvalid_loader = DataLoader(dataset = valid_data,\n                          batch_size = batch_size, \n                          #sampler = valid_sampler <- WeightedRandomSampler,\n                          shuffle = False,\n                          num_workers=2)","metadata":{"execution":{"iopub.status.busy":"2021-11-30T20:45:37.483695Z","iopub.execute_input":"2021-11-30T20:45:37.484513Z","iopub.status.idle":"2021-11-30T20:45:37.492163Z","shell.execute_reply.started":"2021-11-30T20:45:37.484478Z","shell.execute_reply":"2021-11-30T20:45:37.491354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checking length \nprint(\"Train loader length = \"+ str(len(train_loader)))\nprint(\"Valid loader length = \"+ str(len(valid_loader)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2.7 Displaying processed image","metadata":{}},{"cell_type":"code","source":"# function for displaying images\ndef imshow(image, ax=None, title=None, normalize=True):\n    \"\"\"\n        Display images\n        args:\n            image(tensor): image to display\n        return:\n            axis with image\n    \"\"\"\n    if ax is None:\n        fig, ax = plt.subplots()\n    image = image.numpy().transpose((1, 2, 0))\n    ax.imshow(image)\n    return ax","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# iterating on images and labels in the train loader\ntrain_images, train_labels = next(iter(train_loader))\nfig, axes = plt.subplots(figsize=(12, 12), ncols=5)\n#displaying 5 images\nfor i in range(5):\n    axe1 = axes[i] \n    imshow(train_images[i], ax=axe1, normalize=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checking image size and label size\nprint(train_images.size())\nprint(train_labels.size())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Configurating and Training the Neural Network ","metadata":{}},{"cell_type":"markdown","source":"## 3.1 Loading and Configuration of the Model","metadata":{}},{"cell_type":"code","source":"# Loading the pretrained version of the VGG16 model\n\nmodel = models.vgg16(pretrained=True)","metadata":{"execution":{"iopub.status.busy":"2021-12-01T15:44:30.951658Z","iopub.execute_input":"2021-12-01T15:44:30.952769Z","iopub.status.idle":"2021-12-01T15:44:31.115516Z","shell.execute_reply.started":"2021-12-01T15:44:30.952077Z","shell.execute_reply":"2021-12-01T15:44:31.114225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We experimented with and without freezing the pretrained parameters, but without freezing them gave better results\n\n#for param in model.parameters():\n    #param.requires_grad = False","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Changing the last layer of the network to fit amount of classes (in our case we have 153 classes)\n\nmodel.classifier[6] = nn.Linear(4096,153)","metadata":{"execution":{"iopub.status.busy":"2021-11-30T20:45:50.800504Z","iopub.execute_input":"2021-11-30T20:45:50.800983Z","iopub.status.idle":"2021-11-30T20:45:50.80999Z","shell.execute_reply.started":"2021-11-30T20:45:50.800946Z","shell.execute_reply":"2021-11-30T20:45:50.809342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking the network architecture\nmodel","metadata":{"execution":{"iopub.status.busy":"2021-11-30T20:45:50.810929Z","iopub.execute_input":"2021-11-30T20:45:50.811144Z","iopub.status.idle":"2021-11-30T20:45:50.821716Z","shell.execute_reply.started":"2021-11-30T20:45:50.811119Z","shell.execute_reply":"2021-11-30T20:45:50.820921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Moving the model to the GPU, if available \nif torch.cuda.is_available():\n    model.cuda()","metadata":{"execution":{"iopub.status.busy":"2021-11-30T20:45:50.823174Z","iopub.execute_input":"2021-11-30T20:45:50.823685Z","iopub.status.idle":"2021-11-30T20:45:50.976433Z","shell.execute_reply.started":"2021-11-30T20:45:50.82365Z","shell.execute_reply":"2021-11-30T20:45:50.975688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.2 Choosing Loss Function and Optimizer with corresponding parameters","metadata":{}},{"cell_type":"code","source":"# Choosing the LossFunction\ncriterion = nn.CrossEntropyLoss()\n\n#Choosing the optimizer and learning rate\noptimizer = optim.Adam(model.parameters(), lr=0.0003)\n# we chose Adam as adaptive optimizer: https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/\n\n#patience = 20\n#early_stopping = EarlyStopping(patience=patience, verbose=True)","metadata":{"execution":{"iopub.status.busy":"2021-11-30T20:45:50.977777Z","iopub.execute_input":"2021-11-30T20:45:50.978016Z","iopub.status.idle":"2021-11-30T20:45:50.983744Z","shell.execute_reply.started":"2021-11-30T20:45:50.977982Z","shell.execute_reply":"2021-11-30T20:45:50.9829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.3 Training the model","metadata":{}},{"cell_type":"code","source":"# Using the Trainingloop from Lab 1\n\n# NUMBER OF EPOCHS TO TRAIN\n\nN_EPOCHS = 12\n\ngrad_Tbank = {}\ngrad_Vbank = {}\ngrad_Tstore = torch.tensor([]).cuda()\ngrad_Vstore = torch.tensor([]).cuda()\navg_Tcounter = 0\navg_Vcounter = 0\n\nepoch_loss, epoch_acc, epoch_val_loss, epoch_val_acc = [], [], [], []\n\n# Implementing the scheduler:\nscheduler = CyclicLR(optimizer, base_lr=0.0001, max_lr=0.001, cycle_momentum=0, step_size_up=1000, mode='triangular2', last_epoch=-1)\n\nfor e in tqdm(range(N_EPOCHS), desc='Epochs'):\n    \n    ### TRAINING LOOP\n    running_loss = 0\n    running_accuracy = 0\n\n    ## Put the network in training mode\n    model.train()\n    \n    for i, batch in enumerate(tqdm(train_loader, desc=\"Training Batches\")):\n    \n        # Get a batch from the dataloader\n        x = batch[0]\n        labels = batch[1]\n\n        # move the batch to GPU\n        x = x.cuda()\n        labels = labels.cuda()\n\n        # Compute the network output\n        y = model(x)\n\n        # Compute the loss\n        loss = criterion(y, labels)\n\n        # Reset the gradients\n        optimizer.zero_grad()\n\n        # Compute the gradients\n        loss.backward()\n        for idx, param in enumerate(model.parameters()):\n            grad_Tbank[idx] = param.grad\n            avg_Tcounter += 1\n\n        # Apply one step of the descent algorithm to update the weights\n        optimizer.step()\n        \n        # Apply one step to the scheduler\n        scheduler.step()\n        \n        ## Compute some statistics\n        with torch.no_grad():\n            running_loss += loss.item()\n            running_accuracy += (y.max(1)[1] == labels).sum().item()\n            grad_Tbank[idx] = grad_Tbank[idx] / avg_Tcounter\n    \n    print(\"Training accuracy:\", running_accuracy/float(len(train_data)),\n        \"Training loss:\", running_loss/float(len(train_data)),\n         \"Training Gradients:\", grad_Tbank[idx])\n  \n    epoch_loss.append(running_loss/len(train_data))\n    epoch_acc.append(running_accuracy/len(train_data))\n    grad_Tstore = torch.cat((grad_Tstore, grad_Tbank[idx]),0)\n  \n    ### VALIDATION LOOP\n    ## Put the network in validation mode\n    model.eval()\n\n    running_val_loss = 0\n    running_val_accuracy = 0\n\n    for i, batch in enumerate(tqdm(valid_loader, desc=\"Validation Batches\")):\n        \n        # Get a batch from the dataloader\n        x = batch[0]\n        labels = batch[1]\n\n        # move the batch to GPU\n        x = x.cuda()\n        labels = labels.cuda()\n\n        # Compute the network output\n        y = model(x)\n\n        # Compute the loss\n        loss = criterion(y, labels)\n\n        # Reset the gradients\n        optimizer.zero_grad()\n        \n        #SApply one step to the scheduler\n        scheduler.step()\n        # Compute the gradients\n        loss.backward()\n        for idx, param in enumerate(model.parameters()):\n            grad_Vbank[idx]=param.grad\n            avg_Vcounter +=1\n\n        # Apply one step of the descent algorithm to update the weights\n        optimizer.step()\n\n        ## Compute some statistics\n        with torch.no_grad():\n            running_val_loss += loss.item()\n            running_val_accuracy += (y.max(1)[1] == labels).sum().item()\n            grad_Vbank[idx] = grad_Vbank[idx] / avg_Vcounter\n\n    print(\"Validation accuracy:\", running_val_accuracy/float(len(valid_data)),\n        \"Validation loss:\", running_val_loss/float(len(valid_data)),\n         \"Validation Gradient:\", grad_Vbank[idx])\n\n    epoch_val_loss.append(running_val_loss/len(valid_data))\n    epoch_val_acc.append(running_val_accuracy/len(valid_data))\n    \n    \n    #Trying to do early stopping --> never actually used it\n    \n    #early_stopping(running_val_loss/len(valid_data), model)\n    #if early_stopping.early_stop:\n       # print(\"Early stopping\")\n       # break","metadata":{"execution":{"iopub.status.busy":"2021-11-30T20:45:50.985479Z","iopub.execute_input":"2021-11-30T20:45:50.986029Z","iopub.status.idle":"2021-11-30T21:18:57.329812Z","shell.execute_reply.started":"2021-11-30T20:45:50.985988Z","shell.execute_reply":"2021-11-30T21:18:57.328476Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Converter function to use for visualization\ndef converter_tensor_to_df(grad):\n    data=grad.cpu()\n    n_array=data.numpy()\n    df = pd.DataFrame(n_array)\n    return df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#These Apply the converter function changing the the gradients in GPU tensors to Data frames making it \n#usable with Seaborn\n\ngrad_Tdf = converter_tensor_to_df(grad_Tbank[idx])\ngrad_TStoreDF = converter_tensor_to_df(grad_Tstore)\ngrad_Vdf = converter_tensor_to_df(grad_Vbank[idx])\ngrad_VStoreDF = converter_tensor_to_df(grad_Vstore)\n\n# This Adds a column name to the constructed Dataframe in order to improve seaborns visualisation ability.\ngrad_Tdf.columns = [\"Tra. Gradient\"]\ngrad_TStoreDF.columns = [\"Tra. Gradient\"]\ngrad_Vdf.columns = [\"Val. Gradient\"]\ngrad_VStoreDF.columns = [\"Val. Gradient\"]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This is visualizes Validation Accuracy\nepoch_val_acc =converter_tensor_to_df(epoch_val_acc)\nepoch_val_acc.columns = [\"Val. Acc\"]\nsns.lineplot(data=epoch_val_acc, palette=[\"orange\"])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This is visualizes Validation Loss\nepoch_val_loss=converter_tensor_to_df(epoch_val_loss)\nepoch_val_loss.columns = [\"Val. Loss\"]\nsns.lineplit(data=epoch_val_loss, palette=[\"orange\"])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This is visualizes Training Loss\nepoch_loss=converter_tensor_to_df(epoch_loss)\nepoch_loss.columns = [\"Training Loss\"]\nsns.lineplit(data=epoch_loss, palette=[\"blue\"])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This visualizes the Training accuracy \nepoch_acc=converter_tensor_to_df(epoch_acc)\nepoch_acc.columns = [\"Training Acc.\"]\nsns.lineplit(data=epoch_acc, palette=[\"blue\"])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This  visualizes the Training gradient of the last epoch\nTdf=sns.lineplot(data=grad_Tdf, palette=[\"blue\"])\nTdf.set(xscale='log');","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This is visualizes the Validation gradient of the last epoch \nVdf=sns.lineplot(data=grad_Vdf, palette=[\"orange\"]);\nVdf.set(xscale='log');","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This is visualizes the Training gradient of the entire model \nTSdf=sns.lineplot(data=grad_TStoreDF, palette=['blue'] )\nTSdf.set(xscale='log');","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This is visualizes Validation gradient of the entire model\nVSdf=sns.lineplot(data=grad_VStoreDF, palette = ['orange'])\nVSdf.set(xscale='log');","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.4 Saving the model","metadata":{}},{"cell_type":"code","source":"# Saving the Model, its state and the Optimzier\n\ncheckpoint = {'model': model,\n              'state_dict': model.state_dict(),\n              'optimizer' : optimizer.state_dict()}\n\ntorch.save(checkpoint, 'checkpoint.pth')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Making the Predictions","metadata":{}},{"cell_type":"markdown","source":"## 4.1 Applying transformations and making predictions","metadata":{}},{"cell_type":"code","source":"# Putting the model into evaluation mode:\n\nmodel.eval()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Transforming the images to fit as model inputs: \n\ntest_transform = transforms.Compose([transforms.Resize(224),\n                                     transforms.ToTensor(),\n                                     transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])","metadata":{"execution":{"iopub.status.busy":"2021-11-30T21:18:57.333559Z","iopub.status.idle":"2021-11-30T21:18:57.333967Z","shell.execute_reply.started":"2021-11-30T21:18:57.333744Z","shell.execute_reply":"2021-11-30T21:18:57.333766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to apply the transforms and unsqueezing the Image\n\ndef image_loader(image_name):\n    image = Image.open(image_name)\n    image = test_transform(image).float()\n    image = Variable(image, requires_grad=True)\n    image = image.unsqueeze(0)  \n    return image.cuda()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating a Panda's Dataframe to store the Predictions\n\ndf_predictions = pd.DataFrame(columns = [\"Image\", \"Prediction\"])\ndf_predictions","metadata":{"execution":{"iopub.status.busy":"2021-11-30T21:18:57.335233Z","iopub.status.idle":"2021-11-30T21:18:57.335742Z","shell.execute_reply.started":"2021-11-30T21:18:57.335496Z","shell.execute_reply":"2021-11-30T21:18:57.335521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Getting the Path of all Testing images\n\nimport glob\nimages_path=glob.glob(test_dir+'/*.jpg')","metadata":{"execution":{"iopub.status.busy":"2021-11-30T21:18:57.337219Z","iopub.status.idle":"2021-11-30T21:18:57.337776Z","shell.execute_reply.started":"2021-11-30T21:18:57.337535Z","shell.execute_reply":"2021-11-30T21:18:57.337559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Making the Predctions for all Images and storing the last Part of the Path (Imagenumber.jpg) and the prediction in a Dataframe\n\nfor link in tqdm(images_path):\n    image = image_loader(link)  # apllying the transformation and getting the tensor\n    pred = model(image).argmax(1)[0].item()  # getting max value to optain prediction\n    df_predictions.loc[len(df_predictions)] = [(link.split(\"/\")[-1]), pred] #appending to the dataframe","metadata":{"execution":{"iopub.status.busy":"2021-11-30T21:18:57.339309Z","iopub.status.idle":"2021-11-30T21:18:57.340201Z","shell.execute_reply.started":"2021-11-30T21:18:57.33995Z","shell.execute_reply":"2021-11-30T21:18:57.339974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking if all Predictions were made\n\nlen(df_predictions)","metadata":{"execution":{"iopub.status.busy":"2021-11-30T21:18:57.341283Z","iopub.status.idle":"2021-11-30T21:18:57.342136Z","shell.execute_reply.started":"2021-11-30T21:18:57.34188Z","shell.execute_reply":"2021-11-30T21:18:57.341904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.2 Ordering Predictions","metadata":{}},{"cell_type":"code","source":"#Goal: ordering the Prediction Dataframe\n\n# Loading the Sample Submission Dataframe\ndf_sample= pd.read_csv(\"/kaggle/input/polytech-nice-data-science-course-2021/polytech/sample_submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-11-30T21:18:57.343223Z","iopub.status.idle":"2021-11-30T21:18:57.344094Z","shell.execute_reply.started":"2021-11-30T21:18:57.343836Z","shell.execute_reply":"2021-11-30T21:18:57.34386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Performing left join between sample submission table and prediction table --> getting the right order\n# Renaming the columns to be accepted as submission\n\ndf_predictions = df_predictions.rename(columns={\"Image\": \"image_name\"})\ndf_final = pd.merge(df_sample,df_predictions,how=\"left\",on=\"image_name\")\ndf_final = df_final.drop(columns = [\"class\"])\ndf_final = df_final.rename(columns={\"Prediction\":\"class\"})","metadata":{"execution":{"iopub.status.busy":"2021-11-30T21:18:57.345187Z","iopub.status.idle":"2021-11-30T21:18:57.346022Z","shell.execute_reply.started":"2021-11-30T21:18:57.345783Z","shell.execute_reply":"2021-11-30T21:18:57.345807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking the final Dataframe\n\ndf_final","metadata":{"execution":{"iopub.status.busy":"2021-11-30T21:18:57.347134Z","iopub.status.idle":"2021-11-30T21:18:57.347981Z","shell.execute_reply.started":"2021-11-30T21:18:57.347742Z","shell.execute_reply":"2021-11-30T21:18:57.347766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.3 Create downloadable File","metadata":{}},{"cell_type":"code","source":"# Naming the final Dataframe and converting to a CSV File\n\nfilename = \"vgg16Last\"\ndf_final.to_csv(filename + \".csv\", index = False)","metadata":{"execution":{"iopub.status.busy":"2021-11-30T21:18:57.351225Z","iopub.status.idle":"2021-11-30T21:18:57.352088Z","shell.execute_reply.started":"2021-11-30T21:18:57.351834Z","shell.execute_reply":"2021-11-30T21:18:57.351858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating a Link to Download the File\n\nos.chdir(r'/kaggle/working')\nfrom IPython.display import FileLink\nFileLink(filename + \".csv\")","metadata":{"execution":{"iopub.status.busy":"2021-11-30T21:18:57.353178Z","iopub.status.idle":"2021-11-30T21:18:57.354042Z","shell.execute_reply.started":"2021-11-30T21:18:57.353794Z","shell.execute_reply":"2021-11-30T21:18:57.353819Z"},"trusted":true},"execution_count":null,"outputs":[]}]}
